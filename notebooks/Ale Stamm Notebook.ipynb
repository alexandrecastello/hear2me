{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb88e0e",
   "metadata": {},
   "source": [
    "# Imports and package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ebf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/.pyenv/versions/3.8.12/envs/hear2me/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from huggingsound import SpeechRecognitionModel\n",
    "from transformers import AutoTokenizer, Wav2Vec2ForCTC\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import IPython\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016abe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installs\n",
    "#!pip install pydub\n",
    "#!pip install leia\n",
    "#!pip install nltk\n",
    "#!pip install hurggingsound\n",
    "#!pip install vaderSentiment\n",
    "#!pip install transformers\n",
    "#!pip install spacy\n",
    "#!pip install openai\n",
    "#!pip install python-dotenv\n",
    "#!pip install googletrans==3.1.0a0\n",
    "#install ffmpeg libary for audio conversion sudo apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55639574",
   "metadata": {},
   "source": [
    "# Data Import and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941358a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tsv with data\n",
    "text_df = pd.read_csv('../raw_data/commonvoicedataset/validated.tsv', sep='\\t', header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d771f295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09e8441e62e3c8da70b667874fa75e96731f6e43e359a1...</td>\n",
       "      <td>common_voice_pt_27283586.mp3</td>\n",
       "      <td>Se esta primeira condição for satisfeita, é se...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12baee49ea5072cfd8392765aeb6d0e518a51a23224aa8...</td>\n",
       "      <td>common_voice_pt_25643625.mp3</td>\n",
       "      <td>Nós temos tempo suficiente.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  09e8441e62e3c8da70b667874fa75e96731f6e43e359a1...   \n",
       "1  12baee49ea5072cfd8392765aeb6d0e518a51a23224aa8...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_pt_27283586.mp3   \n",
       "1  common_voice_pt_25643625.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Se esta primeira condição for satisfeita, é se...         2           0   \n",
       "1                        Nós temos tempo suficiente.         2           1   \n",
       "\n",
       "   age gender accents locale segment  \n",
       "0  NaN    NaN     NaN     pt     NaN  \n",
       "1  NaN    NaN     NaN     pt     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3536d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with samples file name and sentence\n",
    "sample = {}\n",
    "for p, s in text_df[['path','sentence']].iloc[0:100].itertuples(index=False):\n",
    "    sample[p] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ceb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert files to wav\n",
    "for file in sample:\n",
    "    sound = AudioSegment.from_mp3(f\"../raw_data/commonvoicedataset/clips/{file}\")\n",
    "    sound = sound.set_frame_rate(16000)\n",
    "    sound.export(f\"../raw_data/{file[:-4]}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c539a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save audios names\n",
    "audio_names = list(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980c7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create paths to audio\n",
    "audio_paths = []\n",
    "for name in audio_names:\n",
    "    audio_paths.append(f\"../raw_data/{name[:-4]}.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ccb62",
   "metadata": {},
   "source": [
    "# Wav2vec Models for transcribing audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/09/2022 15:14:42 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|▎| 29/100 [00:33<02:00,  1.69s/"
     ]
    }
   ],
   "source": [
    "#use Wav2Vec model from huggingsound\n",
    "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\")\n",
    "\n",
    "transcriptions = model.transcribe(audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e8fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create list of transcriptions results\n",
    "transcriptions_list = []\n",
    "for transcript in transcriptions:\n",
    "    transcriptions_list.append(transcript['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79148287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample dataframe with filename and sentence\n",
    "sample_df = pd.DataFrame(list(sample.items()), columns=['file_name', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26295fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add transcribed sentence list\n",
    "sample_df['transc_sentence'] = transcriptions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sample df\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6361a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check true sentences vs transcribed sentences \n",
    "for i, j in sample_df.iterrows():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bf716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test another model\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Edresson/wav2vec2-large-xlsr-coraa-portuguese\")\n",
    " \n",
    "model_2 = SpeechRecognitionModel(\"Edresson/wav2vec2-large-xlsr-coraa-portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d2eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcriptions_2 = model_2.transcribe(audio_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf963455",
   "metadata": {},
   "source": [
    "## Comparing transcriptions to actual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of transcriptions results\n",
    "transcriptions_list_2 = []\n",
    "for transcript in transcriptions_2:\n",
    "    transcriptions_list_2.append(transcript['transcription'])\n",
    "    \n",
    "#create sample dataframe with filename and sentence\n",
    "sample_df_2 = pd.DataFrame(list(sample.items()), columns=['file_name', 'sentence'])\n",
    "\n",
    "#add transcribed sentence list\n",
    "sample_df_2['transc_sentence'] = transcriptions_list_2\n",
    "\n",
    "#check true sentences vs transcribed sentences \n",
    "for i, j in sample_df_2.iterrows():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425995a",
   "metadata": {},
   "source": [
    "## Tests with sample audios from WhatsApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import audio from Senna speech\n",
    "senna_sound = AudioSegment.from_ogg(\"../raw_data/senna.ogg\")\n",
    "senna_sound = senna_sound.set_frame_rate(16000)\n",
    "senna_sound.export(f\"../raw_data/senna.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a371e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transcribe Senna audio with model 1\n",
    "senna_transc = model.transcribe([\"../raw_data/senna.wav\"])\n",
    "senna_transc[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe Senna audio with model 2\n",
    "senna_transc_2 = model_2.transcribe([\"../raw_data/senna.wav\"])\n",
    "senna_transc_2[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sample WhatsApp audio\n",
    "w_audio = AudioSegment.from_ogg(\"../raw_data/audio_test.ogg\")\n",
    "w_audio = w_audio.set_frame_rate(16000)\n",
    "w_audio.export(f\"../raw_data/audio_test.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe sample audio with model 2\n",
    "w_audio = model_2.transcribe([\"../raw_data/audio_test.wav\"])\n",
    "w_audio[0]['transcription']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f0378",
   "metadata": {},
   "source": [
    "# LDA Approach to summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a143243",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87963b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#remove stop words\n",
    "\n",
    "stop_words = stopwords.words('portuguese')\n",
    "\n",
    "def rmv_sw(text):\n",
    "    word_tokens = word_tokenize(text) \n",
    "    text = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(text)\n",
    "\n",
    "texto_audio_w =  rmv_sw(w_audio[0]['transcription'])\n",
    "\n",
    "texto_senna = rmv_sw(senna_transc_2[0]['transcription'])\n",
    "texto_senna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc6f02",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LDA to extract main topics from text\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def print_topics(texto):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_df = 2).fit([texto])\n",
    "\n",
    "    data_vectorized = vectorizer.transform([texto])\n",
    "\n",
    "    lda_model = LatentDirichletAllocation(n_components=1).fit(data_vectorized)\n",
    "    \n",
    "    for idx, topic in enumerate(lda_model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac52402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print topics from texto_senna\n",
    "\n",
    "print_topics(texto_senna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea91a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print topics from auido_w\n",
    "\n",
    "print_topics(texto_audio_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfdde7",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis\n",
    "\n",
    "#Use portuguese sentiment analysis lib\n",
    "\n",
    "from libs.leia.leia import SentimentIntensityAnalyzer\n",
    "\n",
    "s = SentimentIntensityAnalyzer()\n",
    "\n",
    "#test sentiment analysis for each audio\n",
    "\n",
    "lista = list(sample_df['sentence'])\n",
    "\n",
    "for frase in lista:\n",
    "    print(frase, s.polarity_scores(frase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451762b",
   "metadata": {},
   "source": [
    "# Spacy library approach to text pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this in bash to download portuguese pipeline: python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86097d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy and load portuguese model\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save text as spacy object\n",
    "texto_completo = nlp(senna_transc_2[0]['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8069103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract tokens from text\n",
    "\n",
    "for token in texto_completo:\n",
    "    print (token, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save portuguese stopwords\n",
    "\n",
    "spacy_stopwords = spacy.lang.pt.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f35e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords from text\n",
    "\n",
    "for token in texto_completo:\n",
    "    if not token.is_stop:\n",
    "        print (token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize words\n",
    "\n",
    "for token in texto_completo:\n",
    "    print (token, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of Speech Tagging\n",
    "\n",
    "for token in texto_completo:\n",
    "    print (token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ba21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract full name from text\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [[{'POS': 'PROPN'}, {'POS': 'PROPN'}]]\n",
    "    matcher.add('FULL_NAME', pattern)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_test = nlp('''Testando capacidade do spacy de detectar nome dentro \n",
    "                 de um texto, Alexandre Carvalho testando pra ver se funciona''')\n",
    "\n",
    "extract_full_name(texto_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacy Visualization\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "#displacy.serve(texto_completo, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "\n",
    "#function for counting word frequency\n",
    "\n",
    "def word_freq(text, count):\n",
    "    nlp = spacy.load('pt_core_news_lg')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    return nlargest(count, word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting words frequencies\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "doc= nlp(texto_completo)\n",
    "tokens=[token.text for token in doc]\n",
    "word_frequencies={}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "max_frequency=max(word_frequencies.values())\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word]=word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc43c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq(texto_completo, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8feca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a773e",
   "metadata": {},
   "source": [
    "# Tests with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(dotenv_path=\"/home/alexandre/code/alexandrecastello/hear2me/notebooks/openai.env\")\n",
    "openai.api_key = os.environ.get('OPENAI_KEY')\n",
    "completion = openai.Completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b06724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analysis(text):\n",
    "    response = openai.Completion.create(\n",
    "  engine=\"text-davinci-002\",\n",
    "  prompt=f\"Summarize and return the sentiment of the following text:{texto}\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "    answer = response.choices[0].text.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"Boa Tarde. Estamos com a esperança de que Abril seja o inicio da recuperação do mercado. Ja estamos sentindo bastante necessidade de comprar coisas novas. A principio estamos priorizando os fornecedores que vendem a prazo, enquanto isso estamos tentando viabilizar mais investimento em novidades. Os primeiros 3 meses do ano foi bastante complicado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0db35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"../raw_data/senna.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text summarization with full text\n",
    "senna_sum = summarize(senna_transc_2[0]['transcription'])\n",
    "senna_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text summarization with clean text\n",
    "summarize(texto_senna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"../raw_data/audio_test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_audio[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text summarization with full text\n",
    "audio_w_sum = summarize(w_audio[0]['transcription'])\n",
    "audio_w_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30162708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text summarization with clean text\n",
    "audio_w_sum = summarize(texto_audio_w)\n",
    "audio_w_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad009c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "result = translator.translate(audio_w_sum, dest='pt').text\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382940d",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "  \n",
    "# adding Folder to the system path\n",
    "sys.path.insert(0, '/home/alexandre/code/alexandrecastello/hear2me/')\n",
    "\n",
    "from transcriber import load_model, transcribe\n",
    "from gpt3 import text_analysis, translate\n",
    "\n",
    "model = load_model()\n",
    "transcribed_text = transcribe(\"../raw_data/senna.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005111d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = text_analysis(transcribed_text)\n",
    "translated_text = translate(analysis)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329fccc",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3279fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar word2vec na lista de palavras do stopwords pra poder aproximar palavras que não estão presentes na lista"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
